# -*- coding: utf-8 -*-
"""Heart _Disease_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qkjIr0tMX5Bo_gH4R7niJ-OhqZbfgXN5
"""

import pandas as pd
import numpy as np

db=pd.read_csv('Heart_Disease_Prediction.csv')
db

x=db.iloc[:,:-1]
y=db.iloc[:,-1]
y

from sklearn.preprocessing import LabelEncoder # use to encode the only lables (single line )
le= LabelEncoder()
y = le.fit_transform(y)
y

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)  # Only transform test data!

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42) # n_estimator decides how many tree in the forest
classifier.fit(x_train, y_train)

y_pred = classifier.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import numpy as np

# Visualize only first two features: Age and Estimated Salary
feature_indices = [0, 1]  # Update this if feature order is different

# Inverse transform to get original scale (only for plotting)
X_set = sc.inverse_transform(x_train)
y_set = y_train

# Create meshgrid
X1, X2 = np.meshgrid(
    np.arange(start=X_set[:, feature_indices[0]].min() - 10, stop=X_set[:, feature_indices[0]].max() + 10, step=1),
    np.arange(start=X_set[:, feature_indices[1]].min() - 1000, stop=X_set[:, feature_indices[1]].max() + 1000, step=500)
)

# Create combined array with meshgrid and other features set to mean
X_combined = np.zeros((X1.size, x_train.shape[1]))
X_combined[:, feature_indices[0]] = X1.ravel()
X_combined[:, feature_indices[1]] = X2.ravel()
x_train_mean = x_train.mean(axis=0)
other_indices = [i for i in range(x_train.shape[1]) if i not in feature_indices]
for idx in other_indices:
    X_combined[:, idx] = x_train_mean[idx]

# Scale combined input
X_combined_scaled = sc.transform(X_combined)
Z = classifier.predict(X_combined_scaled).reshape(X1.shape)

# Plotting
plt.figure(figsize=(10,6))
plt.contourf(X1, X2, Z, alpha=0.75, cmap=ListedColormap(('salmon', 'dodgerblue')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())

# Plot training points
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, feature_indices[0]], X_set[y_set == j, feature_indices[1]],
                c=ListedColormap(('salmon', 'dodgerblue'))(i), label=j)

plt.title('Random Forest Classification (Training set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.tight_layout()
plt.show()

import pickle

# Assuming your trained model is in a variable called `model`
with open('model.pkl', 'wb') as f:
    pickle.dump(classifier, f)

from google.colab import files
files.download('model.pkl')